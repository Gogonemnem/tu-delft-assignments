{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7c5fe867793545bf83d0c7c52323a63",
     "grade": false,
     "grade_id": "cell-a9dbaece96fc4d1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# High Dynamic Range (HDR)\n",
    "\n",
    "## Capture\n",
    "The (digital) sensor of a camera is only able to measure accurately within a certain luminance range. This range can change between photos but it limits the *dynamic range* of a single picture. Taking a picture with the sun in the background for example will often result in pitch black shadows without any detail.\n",
    "![HDR capture](https://cdn-files.cloud/wp-content/blogs.dir/68/files/2017/08/smartphone-camera-tips-HDR.jpg)\n",
    "You might have noticed that your smartphone's camera app has a HDR button. With this mode enabled it will take multiple pictures at different exposure levels (which shifts the luminance range that the camera is able to capture) and use clever algorithms to combine them together. Similar results can also be achieved with a DLSR by taking multiple photos and using computer software to combine them into a single image. Although digital cinema camera have a large dynamic range by their own, some of the [latest cinema cameras](https://www.red.com/red-101/hdrx-high-dynamic-range-video) are even capable of applying this same \"HDR trick\" to video.\n",
    "\n",
    "Apart from real-world capture, computer generated images (CGI) in movies have been using high dynamic range outputs for decades. Even modern video games have shifted to using physically based metrics for light intensities.\n",
    "\n",
    "## Display\n",
    "As discussed in the color notebook, computer images often store colors as 8-bit RGB values. With 8 bits we can only store 256 different values per color channel. This is obviously not enough to store the large range of values that was captured in HDR. Furthermore, there is no clear definition of what the actual displayed luminance should be. This completely depends on your screens capabilities and brightness settings.\n",
    "\n",
    "In the last couple of years TV manufacturers have been pushing for a HDR formats such that we can store/transfer and display HDR images. HDR10 for example uses 10 bits per color channel for 4 times as many values per channel, and Dolby Vision further increases this to 12 bits per channel. HDR10+ and Dolby Vision also take advantage of the fact that most frames in a movie only contain a subrange (compared to the full range that can be captured) of intensities. Both technologies store the minimum and maximum intenisty values for each frame. The color channel values describe the pixels intensities relative to the range of that frame. This way even higher precision can be achieved as long as the minimum and maximum intensities are relatively close together.\n",
    "\n",
    "# Tone Mapping\n",
    "Unfortunately, no existing monitor or TV is even remotely capable of displaying all possible light intensities. Most (older) devices are not even capable of interpreting these HDR signals nor are they capable of producing the desired light colors and intensities. We refer to these as Standard Dynamic Range devices as they have a low dynamic range (which has long been the standard).\n",
    "\n",
    "![HDR display](https://www.tftcentral.co.uk/images/hdr/hdr_demo.jpg)\n",
    "\n",
    "In both cases we need a way of mapping our HDR signal to something that the device is actually capable of displaying. This processing of mappimg a HDR signal to a lower range is called tone mapping.\n",
    "\n",
    "Many tone mapping algorithms exist, from the very simple ones such as the ones used in video games to complex and computationally expensive algorithms used for image editing and post processing. In the following assignments you will implement a tone mappping algorithm that will get you acquinted with the fundamental principles of complex tone mapping pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "782639551683f395e33fb456e838e959",
     "grade": false,
     "grade_id": "cell-71c4b05f5acbfba3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.ndimage\n",
    "import os\n",
    "# helpers.py is one level up in the directory structure so we need to tell Python were to find it\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c30c5a03855fe4de17c1711e8c5abf31",
     "grade": false,
     "grade_id": "cell-029f2ed6846d479e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following images will be used in the exercises. As you can see, both greatly exceed our \"SDR\" range and hence both display as purely white (all pixels are $>1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo1_hdr = helpers.imread_hdr(os.path.join(helpers.dataset_folder, \"week1\", \"hdr\", \"nancy_cathedral.exr\"))\n",
    "photo2_hdr = helpers.imread_hdr(os.path.join(helpers.dataset_folder, \"week1\", \"hdr\", \"nancy_cathedral_2.exr\"))\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Nancy Cathedral (1) in HDR (your solution)\": photo1_hdr,\n",
    "    \"Nancy Cathedral (2) in HDR (your solution)\": photo2_hdr,\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a092f43d95fe5aac48de7431d63bf56",
     "grade": false,
     "grade_id": "cell-cefb265f071f8db5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 7 (1 point)\n",
    "A naive way of tonemapping is to offset and (linearly) stretch the color channels such that they ranges from 0 to $s$ (similar to contrast stretching). Here, $s$ acts as the scaling factor and allows some part of the image to be clipped ($>1.0$). This ensures that bright highlights remain bright without underexposing the rest of the image.\n",
    "\n",
    "Implement a tone mapping function that offsets/stretches each of the color channels such that it ranges from 0 to $s$ and find a suitable scaling factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd48985f1254a360c84c4767339d4ceb",
     "grade": false,
     "grade_id": "exercise7",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def stretch_color_tonemap(hdr_image, s):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "photo1_hdr = helpers.imread_hdr(os.path.join(helpers.dataset_folder, \"week1\", \"hdr\", \"nancy_cathedral.exr\"))\n",
    "photo2_hdr = helpers.imread_hdr(os.path.join(helpers.dataset_folder, \"week1\", \"hdr\", \"nancy_cathedral_2.exr\"))\n",
    "\n",
    "photo1_sdr = stretch_color_tonemap(photo1_hdr, 200.0)\n",
    "photo2_sdr = stretch_color_tonemap(photo2_hdr, 200.0)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Nancy Cathedral (1) in SDR (your solution)\": photo1_sdr,\n",
    "    \"Nancy Cathedral (2) in SDR (your solution)\": photo2_sdr,\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ad4cc143c22699ca5cd79159d1c435d",
     "grade": true,
     "grade_id": "exercise7_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6d8f0883a54ddb38582f52d390a57b2",
     "grade": false,
     "grade_id": "cell-ca8a7149a53baabd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 8 (2 points)\n",
    "Simply scaling the contrast doesn't work very well for images with large dynamic range because it also compressed the image details. We therefor need a more complex *tonemapping* operator to convert an HDR signal into standard dynamic range which can be displayed by our monitors.\n",
    "\n",
    "In this exercise you will implement the tonemapping function that was described in the first lecture. In summary, the algorithm consists of the following steps:\n",
    " * Compute the intensity of the image ($\\text{intensity}=0.35*R+0.45*G+0.2*B$)\n",
    " * Separate color from the intensity ($\\text{color}=(R,G,B)/\\text{intensity}$)\n",
    " * Compute the large scale intensity using a bilateral filter (`cv2.bilateralFilter(intensity, -1, 2, 2)`)\n",
    " * Compute the layer that stores local details\n",
    " * Reduce the contrast of the large scale layer by rescaling it to a range of $0$ to $s$ (same as exercise 7)\n",
    " * Combine the modified large scale layer with the detail layer to create a new intensity layer.\n",
    " * Finally, combine the intensity- and color layers to create the new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c83cfd37ea90cbdbe0828930887b5fd",
     "grade": false,
     "grade_id": "exercise8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def local_tonemap(hdr_image, s):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "photo1_hdr = helpers.imread_hdr(os.path.join(helpers.dataset_folder, \"week1\", \"hdr\", \"nancy_cathedral.exr\"))\n",
    "photo2_hdr = helpers.imread_hdr(os.path.join(helpers.dataset_folder, \"week1\", \"hdr\", \"nancy_cathedral_2.exr\"))\n",
    "\n",
    "photo1_sdr = local_tonemap(photo1_hdr, 200.0)\n",
    "photo2_sdr = local_tonemap(photo2_hdr, 200.0)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Nancy Cathedral (1) in SDR (your solution)\": photo1_sdr,\n",
    "    \"Nancy Cathedral (2) in SDR (your solution)\": photo2_sdr,\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f95bac0e8502424dae1ad240cca765eb",
     "grade": true,
     "grade_id": "exercise8_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
