{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "886147079dfe1253e19e045d365c02d5",
     "grade": false,
     "grade_id": "cell-91ecdd51e335450e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import scipy.signal\n",
    "import os\n",
    "# helpers.py is one level up in the directory structure so we need to tell Python were to find it\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "local_data_folder = os.path.join(helpers.dataset_folder, \"week3\", \"collections\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f078f78d2c57e3a7efe0d61a0d542858",
     "grade": false,
     "grade_id": "cell-8315cc1f829f08c5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Searching image collections\n",
    "\n",
    "In the previous excercises we have seen how an image can be inpainted without access to additional information. Yet, such an approach is limited in the variety of content it can produce. We can achieve much richer and more constent inpainting by copying existing image content from a similar image. For that we need a source of such images - an image collection. Furthermore, we need a fast and reliable way how to find good matches to our query image.\n",
    "\n",
    "While we could potentially compare images pixel by pixel using the Sum of Squared Distances metric, a more efficient and often more robust approach is to utilize lower-dimensional image descriptors. One of the simplest choices is *GIST*.\n",
    "\n",
    "The name *GIST* refers to the idea of extracting the gist of the image. GIST is a simple fixed-length vector of real numbers that summarizes distribution of contrast (or gradients in the image). It is built by averaging intensity of edges detected in several image regions, at several scales and several orientations.\n",
    "\n",
    "In this assignment, we will compute GIST of an image and then use it to find similar images in a preprocessed image collection.\n",
    "\n",
    "### GIST algorithm\n",
    "There are several ways how to build a GIST descriptor. In this Assignment we apply a sequence of image convolutions (see Assignment 1.1) with differently oriented and sized Gabor filters. The results of each convolution are then split into a fixed-sized grid and averaged to obtain entries for the descriptor. Finally, a low resolution version of the image is appended to the final descriptor to encode the average color distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e5781c84fb5baecefa841b849c17aba",
     "grade": false,
     "grade_id": "cell-8cf1d83c8ef069f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 7 (2 points)\n",
    "\n",
    "The coefficients of the GIST descriptor are composed of image gradients detected at differet scales (representing range of spatial frequencies) and different orientations. \n",
    "\n",
    "We have previously used specialized filters to detect sharp edges (high frequency) with either horizontal or vertical orientation. \n",
    "Gabor filter (or Gabor patches) are a generalization of edge detection that is inspired by processing in human visual cortex.\n",
    "\n",
    "\n",
    "<img src=\"gabor.png\" alt=\"Gabor filter\" style=\"width:20%\">\n",
    "\n",
    "\n",
    "A Gabor filter $f(x,y)$ is a product of a symmetrical bi-variate Gaussian filter\n",
    "$$\n",
    "g(x,y) = e^{-\\frac{1}{2}\\frac{x^2+y^2}{\\sigma^2}}\n",
    "$$\n",
    "and a sinusoidal corrugation\n",
    "$$\n",
    "s(x,y) = \\sin\\left((x \\cos(\\alpha) - y \\sin(\\alpha)) \\cdot f\\right)\n",
    "$$\n",
    "with parameters\n",
    "- $\\sigma$ as a standard deviation controlling the width of the filter,\n",
    "- $\\alpha$ as an angle (in radians) controlling the orientation of the filter (and detected gradients)\n",
    "- $f$ as a spatial frequency controling the sensitivity of the filter to sharp or smooth gradients.\n",
    "\n",
    "Finally, the entire Gabor filter is\n",
    "$$\n",
    "f(x,y) = g(x,y) \\cdot s(x,y) \\cdot \\left( \\sum_{x,y} g(x,y) \\right)^{-1}\n",
    "$$\n",
    "where the denominator on the right normalizes the sum of the Gaussian component to one. \n",
    "\n",
    "This normalization ensures that the response of the filter stays normalized regardless of the discretization to fixed-resolution pixel grid of size $s$.\n",
    "\n",
    "\n",
    "### Task\n",
    "Implement a method that returns `size` $\\times$ `size` kernel of the Gabor filter as defined above.\n",
    "The domain of the spatial variables $x$, $y$ covers the range $[-1, 1]$, that is $(x,y)\\in[-1,1]\\times[-1,1]$.\n",
    "\n",
    "### Tips\n",
    "Try how the filter changes for different choices of $\\sigma$, $\\alpha$ and $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7ccb05906556b6ef95f7b3cfd58d175",
     "grade": false,
     "grade_id": "exercise7_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_gabor_filter(size, sigma, f, alpha):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return gabor_filter\n",
    "    \n",
    "gabor_filter = build_gabor_filter(35, 1.0/3.2, 8, np.radians(60))\n",
    "    \n",
    "helpers.show_images({\n",
    "    'Output kernel': gabor_filter / gabor_filter.max() * 0.5 + 0.5,\n",
    "    'Reference kernel': helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, 'gabor1.png')),\n",
    "}, nrows=1, ncols=2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d12018a7bd5b63d4e43a3214a8d7fae",
     "grade": false,
     "grade_id": "cell-e2d33184b6732da9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 7\n",
    "Make sure that your solution matches the references kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a11be321fcc62b8e7329caee3dd96ea",
     "grade": true,
     "grade_id": "exercise7a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e299e54221c473bfc3563d966d33a0a",
     "grade": true,
     "grade_id": "exercise7b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7eb727f4452ece297c2b1081b21bb661",
     "grade": false,
     "grade_id": "cell-2602ee05bb637eed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8 (4 points)\n",
    "\n",
    "The next step is to apply the filter $f(x,y)$ to a grayscale image $I(x,y)\\in\\mathcal{R}^{H\\times W}$ using convolution. The Gabor filter response $r(x,y) = I(x,y) * f(x,y)$ has a sign that depends on the mutual orientation of the filter and the gradient. In this excercise the sign does not matter and therefore we return absolute value of the response $r_a(x,y) = |r(x,y)|$.\n",
    "\n",
    "The filter response is expected to have the same resolution as the input image. However, we need the GIST descriptor to be relatively small. Therefore, we bin the response values into a `grid_size` $\\times$ `grid_size` 2D histogram $H(i,j)$ where each bin contains mean of $r_a(x,y)$ for the pixels that are covered by that bin.\n",
    "\n",
    "### Task\n",
    "First, implement a method that for a given grayscale image returns an absolute Gabor filter response.\n",
    "Second, implement a method that bins this response into a 2D histogram as defined above.\n",
    "\n",
    "### Tips\n",
    "- You can assume that the image size is divisible by the `grid_size`.\n",
    "- You are allowed to use `scipy.signal.convolve2d(image, kernel, mode=\"same\")`\n",
    "- Exlore how the response of the filter changes for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef897548772418a8a3b9b0e356630477",
     "grade": false,
     "grade_id": "exercise8_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_absolute_response(image, filter_size, sigma, f, alpha):\n",
    "    # Use scipy.signal.fftconvolve for better performance.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return abs_response, gabor_filter\n",
    "    \n",
    "def bin_values(vals, grid_size):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #return binned_values\n",
    "    \n",
    "image = helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"grad_test.png\"))\n",
    "\n",
    "response, gabor_filter = get_absolute_response(image, 32, 1.0/3.2, 8, np.radians(45))\n",
    "binned = bin_values(response, 4)\n",
    "    \n",
    "helpers.show_images({\n",
    "    'Input Image': image,\n",
    "    'Your Filter': gabor_filter / gabor_filter.max() * 0.5 + 0.5,\n",
    "    'Your Response': response / response.max(),\n",
    "    'Your Binned': plt.get_cmap('gray')(binned / binned.max())\n",
    "}, nrows=1, ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88ab7beead53180c2189373d2dfa44a8",
     "grade": false,
     "grade_id": "cell-46a068273c0b7547",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 8\n",
    "You can test your `bin_values(vals, grid_size)` function by creating a small and simple test image. Work out by hand what the binned image should look like and verify that your solution matches what you expect. The code below checks some basic properties such as the size of the returned image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21c9682b184fa8c3bd578c212b6a37a8",
     "grade": true,
     "grade_id": "exercise8a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"grad_test.png\"))\n",
    "response, gabor_filter = get_absolute_response(image, 32, 1.0/3.2, 8, np.radians(45))\n",
    "assert(gabor_filter.shape == (32, 32))\n",
    "assert(response.shape == image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b485c938f6c5816d17ec7dea4ea5a634",
     "grade": true,
     "grade_id": "exercise8b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5705a2352cdf1fed1a889ecb8a165b31",
     "grade": false,
     "grade_id": "cell-d6e05bc8fffb4433",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 9 (5 points)\n",
    "Finally, a *GIST* descriptor is formed by concatenation of flattened histograms $H_k$ for Gabor filters $g_k$ with different scales and orientations. Here is an example of a small filter bank with 3 different sizes $s$,= and 4 orientations $\\alpha$:\n",
    "\n",
    "<img src=\"gabors_4x3.png\" alt=\"Gabor filters\" style=\"width:60%\" />\n",
    "\n",
    "\n",
    "If we further consider a histogram size of $2\\times2$, we obtain a GIST descriptor as a 1D vector with $3\\times4\\times2\\times2 = 48$ values (for this particular choice of parameters). \n",
    "The GIST vector features one entire histogram row after another and this is repeated first for every orientation $\\alpha$ and then for every scale $s$, so that the order is:\n",
    "$$\n",
    "[s_0,\\alpha_0,y_0,x_0], [s_0,\\alpha_0,y_0,x_1],\\cdots[s_0,\\alpha_0,y_1,x_0],\\cdots[s_0,\\alpha_1,y_0,x_0],\\cdots[s_1,\\alpha_0,y_0,x_0],\\cdots[s_S,\\alpha_A,y_Y,x_X].\n",
    "$$\n",
    "\n",
    "The GIST alone only describes the distribution of gradients in the image. To make it more powerfull, we append one more histogram describing the distribution of the colors in the image similarly as shown for the collection-based inpainting in the lecture.\n",
    "This color histogram is built the same way as previously but instead of the filter response it averages the RGB value of the image. When appeneded at the end of the descriptor, it adds another `grid_size` $\\times$ `grid_size` $\\times 3$ values that correspond to a flattened 2D color histogram with an order:\n",
    "\n",
    "$$\n",
    "[y_0,x_0,R],[y_0,x_0,G],[y_0,x_0,B],\\cdots[y_0,x_1,R],[y_0,x_1,G],[y_0,x_1,B],\\cdots[y_1,x_0,R],[y_1,x_0,G],[y_0,x_1,B],\\cdots\n",
    "$$\n",
    "\n",
    "The final descriptor for this assignment is then defined as\n",
    "$\\mathbf{d} = [\\textrm{GIST} \\cdot w_{grad}, H_{RGB}]$\n",
    "where $w_{grad}$ is additional weight scalar that scales the contribution of the gradients.\n",
    "\n",
    "### Task\n",
    "Implement a method that computes a full descriptor of given RGB image including the RGB appendix. \n",
    "Cover all combinations of sizes $s$ and orientations $\\alpha$.\n",
    "\n",
    "### Tips\n",
    "- The histogram method developed in previous excercise can be easily adapted to compute the RGB histogram.\n",
    "- Visualize the individual filters and their responses in a similar grid as shown in the exercise to better understand what each filter scale and orientation does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc90e5e5fb55430daff84e0c2f620e57",
     "grade": false,
     "grade_id": "cell-36f1a57a16bd2ebd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def image_rgb_to_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def build_gist_descriptor(image, filte_sizes, alphas, sigma, f, grid_size, grad_weight):\n",
    "    # Use image_rgb_to_grayscale() to convert the RGB image to grayscale.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return descriptor\n",
    "    \n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"spatenv/opencountry_land228.jpg\"))\n",
    "\n",
    "    \n",
    "filter_sizes = np.array([9,17,33,65])\n",
    "alphas = np.radians(np.arange(6, dtype=float)/6*180)\n",
    "sigma = 1.0 / 3.2\n",
    "f = 8\n",
    "grid_size = 4\n",
    "grad_weight = 20\n",
    "descriptor = build_gist_descriptor(image, filter_sizes, alphas, sigma, f, grid_size, grad_weight)\n",
    "\n",
    "\n",
    "# Visualize.\n",
    "dsize = grid_size**2\n",
    "s_maxs = np.array([descriptor[i*(dsize*len(alphas)):(i+1)*(dsize*len(alphas))].max() for i in range(len(filter_sizes))])\n",
    "panels = {}\n",
    "for i, (s, a) in enumerate(itertools.product(filter_sizes, alphas)):\n",
    "    d = descriptor[i*dsize:(i+1)*dsize].reshape(grid_size, grid_size)\n",
    "    panels[f's={s} a={np.degrees(a):.0f}'] = plt.get_cmap('viridis')(d / s_maxs[filter_sizes==s])\n",
    "panels['RGB'] = descriptor[-(dsize*3):].reshape(grid_size,grid_size,3)\n",
    "skeys = ['s=9 a=0','s=17 a=60', 's=33 a=90', 's=65 a=120', 'RGB']\n",
    "panels = {f'Your {k}': panels[k] for k in skeys}\n",
    "panels.update({f'Refer. {k}': helpers.imread_normalized_float(os.path.join(local_data_folder, f\"codes/{k.replace('=', '_')}.png\")) for k in skeys})\n",
    "helpers.show_images(panels, nrows=2, ncols=len(skeys), col_height=2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce426c9bee74417c92a1396509a6605d",
     "grade": false,
     "grade_id": "cell-3a827c565358ac08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 3\n",
    "Compare your solutions to the provided reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28cfc46981028a91edf2dcf98d9a7eff",
     "grade": true,
     "grade_id": "exercise9a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f541ad4f47e694592e7c0e9869c4b6b",
     "grade": true,
     "grade_id": "exercise9b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20d8752501bb0c03a7351ed407c0e824",
     "grade": false,
     "grade_id": "dgdfgdfgdfg342",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 10 (4 points)\n",
    "\n",
    "We can now use the resulting descriptor to quickly find a set of $k$ most similar images in potentially large image collection which would take a long time to compare pixel-by-pixel. \n",
    "\n",
    "In this exercise we will find the most similar image by minimizing the L2 distance between the query image descriptor $\\mathbf{d}$ and the collection image descriptors $\\mathbf{d}_i$ such that the index of the most similar image $j$ is\n",
    "$$\n",
    "j = \\arg\\min_{i} ||\\mathbf{d} - \\mathbf{d}_i||^2_2.\n",
    "$$\n",
    "\n",
    "This is useful for exploring large image collections where a search engine can suggest other images similar to the one we are looking at. It can also be used for a coarse categorization of images (coast, mountains, road, city,...) and in the lecture we have seen that a similar image can be used for image inpainting. \n",
    "\n",
    "Note, that for an effective implementation, we must ignore the pixels that are marked as invalid in a provided inpainting mask $M$. That means that every convolution has to carefully avoid sampling the invalid pixels which results in a more complex and slow implementation This is why in this exercise we simulate similar effect by modifying the query image.\n",
    "\n",
    "### Task\n",
    "\n",
    "Implement a method that replaces marked pixels in a given RGB image $\\mathbf{I} \\in \\mathcal{R}^{H \\times W \\times 3}$ with pixels from the most similar image in a provided image collection. \n",
    "The marked pixels are encoded by zeros in the provided mask $M \\in [0,1]^{H \\times W}$.\n",
    "Find the most similar image by minimizing the L2 descriptor norm as shown above.\n",
    "To compute the query image descriptor, use a modified query image generated from the input image by replacing the invalid pixels ($M = 0$) by a uniform gray color ($[0.5, 0.5, 0.5]$).\n",
    "Return the modified query image, the most similar collection image and the inpainted image.\n",
    "\n",
    "\n",
    "### Tips\n",
    "- The descriptors for all images in the dataset are provided and do not need to be recomputed.\n",
    "- Visualize several of the most similar and also several of the least similar images. \n",
    "- Test the query with your own image. Note that the metric is only effective if the collection contains a very close match of the query image. In practice, that means that collections of milions of images are needed. In this example we only use a very small collection of pre-selected image samples.\n",
    "\n",
    "Images courtesy of [8 Scene Categories Dataset](http://people.csail.mit.edu/torralba/code/spatialenvelope/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfbeaade595266bb6035a03bffc63da2",
     "grade": false,
     "grade_id": "exercise10_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def inpaint_image(image, mask, dataset_descriptors, dataset_files, \n",
    "                 filter_sizes, alphas, sigma, f, grid_sizes, grad_weight):\n",
    "    # Use helpers.imread_normalized_float(dataset_files[i]) to read an image i\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #return query_image, nearest_image, inpainted_image \n",
    "\n",
    "filter_sizes = np.array([9,17,33,65])\n",
    "alphas = np.radians(np.arange(6, dtype=float)/6*180)\n",
    "sigma = 1.0 / 3.2\n",
    "f = 8\n",
    "grid_size = 4\n",
    "grad_weight = 20\n",
    "\n",
    "dataset_files = sorted(helpers.list_files_in_folder(os.path.join(local_data_folder, \"spatenv\"), filter=\"*.jpg\"))\n",
    "dataset_descriptors = np.load(os.path.join(local_data_folder, 'spatenv_descs.npy'))\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"opencountry_land493.jpg\"))\n",
    "mask = np.zeros(image.shape[:2])\n",
    "mask[:image.shape[0]//2] = 1\n",
    "\n",
    "query, nearest, inpainted = inpaint_image(image.copy(), mask, dataset_descriptors, dataset_files,\n",
    "                                        filter_sizes, alphas, sigma, f, grid_size, grad_weight)\n",
    "                                        \n",
    "helpers.show_images({\n",
    "    'Your Input': image,\n",
    "    'Your Query': query,\n",
    "    'Your Nearest': nearest,\n",
    "    'Your Result': inpainted\n",
    "}, nrows=1, ncols=4, col_height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39a52ab562d1b6973bd8a10d8a54671d",
     "grade": false,
     "grade_id": "cell-8075b99c15122bf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 10\n",
    "Have a look at the set of images in the data set (`datasets/week3/collections/spatenv/` folder). Is the image picked by your algorithm close to the query image (compared to the other images in the data set)? Try different query images and check if this is still the case.\n",
    "\n",
    "The code below checks some basic properties such as the size of the returned images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a730c4f52e9fe347d29fac6ffd54a061",
     "grade": true,
     "grade_id": "exercise10",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "filter_sizes = np.array([9,17,33,65])\n",
    "alphas = np.radians(np.arange(6, dtype=float)/6*180)\n",
    "sigma = 1.0 / 3.2\n",
    "f = 8\n",
    "grid_size = 4\n",
    "grad_weight = 20\n",
    "\n",
    "dataset_files = sorted(helpers.list_files_in_folder(os.path.join(local_data_folder, \"spatenv\"), filter=\"*.jpg\"))\n",
    "dataset_descriptors = np.load(os.path.join(local_data_folder, 'spatenv_descs.npy'))\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"opencountry_land493.jpg\"))\n",
    "mask = np.zeros(image.shape[:2])\n",
    "mask[:image.shape[0]//2] = 1\n",
    "\n",
    "query, nearest, inpainted = inpaint_image(image.copy(), mask, dataset_descriptors, dataset_files,\n",
    "                                        filter_sizes, alphas, sigma, f, grid_size, grad_weight)\n",
    "assert(query.shape == image.shape)\n",
    "assert(nearest.shape == image.shape)\n",
    "assert(inpainted.shape == image.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
