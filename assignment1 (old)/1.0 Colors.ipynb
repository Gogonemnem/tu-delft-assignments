{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de5602c36daec6ac682c2a193c09524e",
     "grade": false,
     "grade_id": "cell-529e512d7226b6d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "This assignment consists of 14 exercises divided over two notebooks. Each exercise will come with some tests that are used to verify whether your code is correct. If you pass these tests then you are rewarded *full points*; if your code fails then you will get *no points*. Make sure to **read the rules** before you start the assignment.\n",
    "\n",
    "## Rules\n",
    "For this assignment the following rules apply:\n",
    "\n",
    "**General**\n",
    " * The assignment should be completed in **groups of three** (enroll in a group on Brightspace).\n",
    " * Any kind of intergroup discussion will be considered fraud and both the parties will be punished.\n",
    " * All code must be written intra group. All external help, with the exception of Python/library documentation and the lecture slides, will be considered fraud.\n",
    " * Do not use libraries that implement the assignment for you (e.g. don't use `cv2.cvtColor` to do color to gray conversion).\n",
    "\n",
    "**Grading**\n",
    " * If a test cell runs without error (warnings are allowed) then you receive full points.\n",
    " * If a test cell throws an error for any reason then you receive 0 points.\n",
    "  * If a cell takes more than five minutes to complete then this is considered an error.\n",
    " * If your code fails a test for *any reason* then you receive 0 points for that exercise.\n",
    " * Your grade is computed as $\\frac{\\text{points}}{\\text{max_points}} * 9+1$ and will be rounded to the closest 0.5 point.\n",
    " * Submit your code to Brightspace as a zip file containing only the notebook (`*.ipynb`) files.\n",
    " * **Do not rename the notebook files**\n",
    " \n",
    "**Late Submissions**\n",
    " * Late submissions must be submitted *as soon as possible* to the \"Assignment 1 - Late Submissions\" assignment on Brightspace.\n",
    " * The following penalty will be applied: $\\text{adjusted grade} = \\text{grade} - 1 - \\lceil\\frac{\\text{minutes late}}{10}\\rceil$\n",
    "\n",
    "<br />\n",
    " \n",
    "**Before you submit**, make sure that you are not accidentaly using any global variables. Restart the kernel (wiping all global variables) and run the code from top to bottom by clicking \"Kernel\" => \"Restart & Run all\" in the menu bar at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3110f0726abfd4680bd5f89e3ca7b484",
     "grade": false,
     "grade_id": "cell-6a3dbf0b3920b539",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "\n",
    "# Load a image, resize (optional) and convert it to a normalized floating point format (map values between 0.0 and 1.0).\n",
    "#image = helpers.imread_normalized_float(\"name_of_image_file.png\")\n",
    "\n",
    "# Show a single image\n",
    "#helpers.show_image(image, \"Text above image\")\n",
    "    \n",
    "# Showing multiple images in a grid (with a given number of rows and columns):\n",
    "# helpers.show_images({\"Text above figure1\": figure1, \"Text above figure2\": \"figure2\"}, nrows, ncols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a390428dbf9827410a4621a5d809dac4",
     "grade": false,
     "grade_id": "cell-22fcaf97470c9083",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Light and colors\n",
    "Light is a combination of electromagnetic waves of different wavelength. Out of this spectrum, we can capture the range of roughly 380-720nm with our eyes. Almost all displays, including the one you are looking at right now, display colors by using only 3 different base colors: red, green and blue. As you've learned in the lectures, we have only three types of cones (color sensors) in our eyes, which explains this amount. The widget below shows a visible color as a combination of red, green and blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ea60a704ea620edb020547c4c7f2c6a",
     "grade": false,
     "grade_id": "cell-7469ee37e689146c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c16cadeb2014c15b3de69d0c30eaa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8a62f9a3cc494b826fc0da89b7626c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='Red', max=1.0), FloatSlider(value=1.0, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import color_spaces\n",
    "color_spaces.draw_rgb_circle_diagram(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b089d5d471d1b6fc6be89edee49702c1",
     "grade": false,
     "grade_id": "cell-b9be868cfb38f583",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 1 (2 points)\n",
    "As your first assignment you are asked to implement a function that takes a color (RGB) and converts it to gray scale. A gray scale image is computed as a weighted sum of the three color channels - this is similar to computing the intensity of an image, as done in the lecture for the flash/no-flash application. Use 0.299, 0.587 and 0.114 as weights for red, green and blue respectively. The output of the function should be a 2D array (since there is only 1 channel per pixel). (Please feel free to experiment with different coefficients - what do you observe? Please do hand in the solution with the above numbers though).\n",
    "\n",
    "**Note:** You do not need to use Numpy for this exercise yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cbfbfdd482b475b33f0d47aaf39767a",
     "grade": false,
     "grade_id": "exercise1_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5f951b8b5b4c04a23d8be6a82ae20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rgb_to_gray_scale(image):\n",
    "    # Image is a 3D array (height, width, color channels).\n",
    "    # Our gray_image is a 2D array with the same first 2 dimensions (height, width).\n",
    "    gray_image = np.zeros(image.shape[:2], dtype=np.float32)\n",
    "    for y in range(gray_image.shape[0]):\n",
    "        for x in range(gray_image.shape[1]):\n",
    "            # YOUR CODE HERE\n",
    "            weights = np.array([0.299, 0.587, 0.114], dtype=np.float32)\n",
    "            gray_image[y, x] = np.sum(np.multiply(image[y,x], weights))\n",
    "    return gray_image\n",
    "\n",
    "new_york_image = helpers.imread_normalized_float(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"newyork.jpg\"), 0.25) # Downscale by 4 in each direction = 16 times less pixels.\n",
    "new_york_image_gray = rgb_to_gray_scale(new_york_image)\n",
    "new_york_image_gray_reference = helpers.rgb2gray(new_york_image)\n",
    "\n",
    "helpers.show_images({ \"Colored Input\": new_york_image, \"Your solution\":  new_york_image_gray, \"Reference\": new_york_image_gray_reference }, nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a988c966a30f2aeb7c71aafc2c6fc88",
     "grade": true,
     "grade_id": "exercise1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68cfc0d74e3a12436c013959f8b16773",
     "grade": false,
     "grade_id": "cell-592e155d85a71fe7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2  (2 points)\n",
    "When you have a working solution (without Numpy), you might find that it takes a couple of seconds before the results become visible. As was mentioned in the tutorial session, Python is a very slow programming language. Processing pixels using for loops is thus not the best solution if we want optimal performance. To achieve better performance we will have to offload as much work as possible to libraries that are written in high performance languages. For this course we will make extensive use of one of such libraries: Numpy.\n",
    "\n",
    "Write a RGB to gray scale function again but this time using only Numpy (no for loops!).\n",
    "\n",
    "*If you are not familiar with Numpy then please take a look at the Numpy tutorial notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "191ae7b96f5226fb3d38602d1a198930",
     "grade": false,
     "grade_id": "exercise2_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your solution to exercise 1:\n",
      "Wall time: 1.53 s\n",
      "\n",
      "Your solution to exercise 2 (with Numpy):\n",
      "Wall time: 5.01 ms\n",
      "\n",
      "Sum of squared differences: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b3d66b01b04f41a07913e966be9bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rgb_to_gray_scale_numpy(image):\n",
    "    weights = np.array([0.299, 0.587, 0.114], dtype=np.float32)\n",
    "    gray_image = np.sum(np.multiply(image, weights), axis=2)\n",
    "    return gray_image\n",
    "\n",
    "# This is at 1/4 resolution (16 times less pixels than the original)...\n",
    "print(\"Your solution to exercise 1:\")\n",
    "%time new_york_image_gray = rgb_to_gray_scale(new_york_image)\n",
    "\n",
    "print(\"\\nYour solution to exercise 2 (with Numpy):\")\n",
    "%time new_york_image_gray_numpy = rgb_to_gray_scale_numpy(new_york_image)\n",
    "\n",
    "# Sum of the differences in pixel values. Use this to verify your solution.\n",
    "# A very small value (< 0.01) means your solution is correct. Small differences are exceptable and are caused by rounding errors.\n",
    "print(f\"\\nSum of squared differences: {helpers.SSD_per_pixel(new_york_image_gray, new_york_image_gray_numpy)}\")\n",
    "\n",
    "helpers.show_images({ \"Your solution (for loop)\": new_york_image_gray, \"Your solution (numpy)\":  new_york_image_gray_numpy }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25212e847a4f90ad6b19186b2fa6a23b",
     "grade": false,
     "grade_id": "cell-07af1eea1114c9e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 2\n",
    "Your solution should create the correct image and be close in performance to the reference (5x slower at most). The following code snippet shows you how much faster/slower your solution is compared to the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51284c7d8f322411a195eb8f18bd68f8",
     "grade": true,
     "grade_id": "exercise2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your solution is 5.32x slower than the reference for image 1\n",
      "Your solution is 5.29x slower than the reference for image 2\n"
     ]
    }
   ],
   "source": [
    "# === TEST 1: New York ===\n",
    "# Test at 1/4 resolution (16 times less pixels than the original).\n",
    "new_york_image_quarter_res = helpers.imread_normalized_float(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"newyork.jpg\"), 0.25) # Downscale by 4 in each direction = 16 times less pixels.\n",
    "new_york_image_quarter_res_gray_reference = helpers.rgb2gray(new_york_image_quarter_res)\n",
    "\n",
    "timer1 = helpers.Timer()\n",
    "with timer1:\n",
    "    for i in range(20):\n",
    "        # Measure execution time with reference solution\n",
    "        new_york_image_quarter_res_gray_reference = helpers.rgb2gray(new_york_image_quarter_res)\n",
    "timer2 = helpers.Timer()\n",
    "with timer2:\n",
    "    for i in range(20):\n",
    "        # Measure execution time with your solution\n",
    "        new_york_image_gray_numpy = rgb_to_gray_scale_numpy(new_york_image_quarter_res)\n",
    "\n",
    "# Your solution may be at most 5 times slower than the reference.\n",
    "print(f\"Your solution is {timer2.elapsed() / timer1.elapsed():.2f}x slower than the reference for image 1\")\n",
    "\n",
    "# === TEST 2: Landscape ===\n",
    "landscape_image = helpers.imread_normalized_float(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"landscape.jpg\"), 0.25)\n",
    "\n",
    "timer1 = helpers.Timer()\n",
    "with timer1:\n",
    "    for i in range(20):\n",
    "        # Measure execution time with reference solution\n",
    "        landscape_image_gray_reference = helpers.rgb2gray(landscape_image)\n",
    "timer2 = helpers.Timer()\n",
    "with timer2:\n",
    "    for i in range(20):\n",
    "        # Measure execution time with your solution\n",
    "        landscape_image_gray_numpy = rgb_to_gray_scale_numpy(landscape_image)\n",
    "\n",
    "# Your solution may be at most 5 times slower than the reference.\n",
    "print(f\"Your solution is {timer2.elapsed() / timer1.elapsed():.2f}x slower than the reference for image 2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a6b1cf22bb89581dbb7a5249cec5f23",
     "grade": false,
     "grade_id": "cell-b7106633cbd2298c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "# Contrast\n",
    "You might be familiar with the various filters on your phone that make the colors in your images stand out more. What these filters do is to increase the contrast of the image. The contrast of an image is defined as the difference between the pixel with the lowest and the pixel with the highest intensity. Let's consider the image of this car for example. The \"colors\" (this is in gray scale) are washed out: the image has a low contrast.\n",
    "\n",
    "Another way we can reason about the contrast of an image is by examining the intensity histogram. A histogram is a collection of bins and each bin stores the frequency of occurances of a certain value range. In the case of images, the values are a color or intensity; so a histogram tells us for each intensity range the amount of pixels that have a corresponding intensity. Next to the car we have plotted a  histogram of the image. Notice how almost all pixels have an intensity between 0.3 and 0.7. The contrast is thus only $0.7-0.3=0.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5600c8c21b4e1f265091c3970e3b4b6",
     "grade": false,
     "grade_id": "cell-b2bd1e8a93b71600",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a211f8caf73f4ef5963cf67fc3f417b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The New York has been heavily edited and has a high contrast. Use a low contrast photo for the following assignments.\n",
    "car_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"car.png\"))\n",
    "\n",
    "hist = np.histogram(car_image, bins=20, range=(0, 1))[0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=helpers.default_fig_size)\n",
    "ax1.imshow(car_image, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax1.set_axis_off()\n",
    "ax2.bar(np.linspace(0, 1, num=20), hist, width=1.0/20)\n",
    "ax2.set_xlabel(\"Intensity (gray scale)\")\n",
    "ax2.set_ylabel(\"Number of pixels\")\n",
    "ax2.set_xlim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6935708e934e42489ad145cd66820cf6",
     "grade": false,
     "grade_id": "cell-1e3abc4110d60371",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3  (1 point)\n",
    "A simple way to increase the contract of an image like this is to \"stretch\" the contrast. We linearly scale the intensities such that the lowest value in the image maps to 0.0 and the highest value maps to 1.0. Implement a function that automatically stretches the contrast such that the intensities range exactly from 0.0 to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "142eb9bf5215dff8672a5dbf964a862a",
     "grade": false,
     "grade_id": "exercise3_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b560aafbdf640afaa468bb8d1c428d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def constrast_stretch(gray_image):\n",
    "    a = np.min(gray_image)\n",
    "    b = np.max(gray_image)\n",
    "    stretch = np.divide(gray_image-a, b-a)\n",
    "    return stretch\n",
    "\n",
    "car_image_stretched = constrast_stretch(car_image)\n",
    "\n",
    "helpers.show_images({ \"Original\": car_image, \"Your solution (stretched contrast)\": car_image_stretched }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "155476aeb45177a575b2504eb00f3d42",
     "grade": false,
     "grade_id": "cell-852f10cb08ef6514",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Testing your solution of exercise 3\n",
    "Contrast stretching should ensure that the histogram now covers the full range of values. The effect of contrast stretching is that we \"smeared out\" the intensities over a larger range. This concept forms the basis for a slightly more advanced contrast enhancement operation called histogram equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4914416403f49e70579680fe6e4b9ab3",
     "grade": false,
     "grade_id": "cell-0af23f0ceecaa6f3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a377a200a44eb1a1cb62c3ceec1e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_intensity_hist(ax, gray_image):\n",
    "    num_bins = 20\n",
    "    hist = np.histogram(gray_image, bins=num_bins, range=(0, 1))[0]\n",
    "    ax.bar(np.linspace(0, 1, num=num_bins), hist, width=1/(num_bins-1) - 0.004)\n",
    "    ax.set_xlabel(\"Intensity (gray scale)\")\n",
    "    ax.set_ylabel(\"Number of pixels\")\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "def plot_histogram_comparison(left_image, right_image, left_title=\"Input\", right_title=\"Comparison\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=helpers.default_fig_size, sharey=True)\n",
    "    plot_intensity_hist(ax1, left_image)\n",
    "    plot_intensity_hist(ax2, right_image)\n",
    "    ax1.set_title(left_title)\n",
    "    ax2.set_title(right_title)\n",
    "    ax2.set_ylabel(\"\") # Hide y labels on the right histogram\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_histogram_comparison(car_image, car_image_stretched, right_title=\"Contrast stretching (your solution)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4049201e52335173c0de54366abc20cc",
     "grade": true,
     "grade_id": "exercise3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "635866ef7e437b0403832a7b29a2660e",
     "grade": false,
     "grade_id": "cell-0725ac6ac2ad1151",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Histogram Equalization\n",
    "The previous method was simple but it only works well on certain images. Imagine for example an image, where most pixels have roughly the same intensity but a couple of outliers (with very low/high intensities) prevent effective contrast stretching.\n",
    "\n",
    "As the name implies, histogram equalization aims to find a function that maps intensities to new intensities such that the histogram is equalized / balanced. To this extent, we first need to understand histograms better. One way to look at them is that they describe the chance of a pixel having a certain intensity. In statistics we describe chance by a probability density function (pdf). The pdf function takes as input the intensity and returns the probability of that intensity occuring at a pixel. A pdf function should always sum up to one over all possible inputs; in the case of the image histogram, we can transform it into a pdf by simply dividing by the number of pixels.\n",
    "\n",
    "We aim to find a mapping function that maps the intensities such that the resulting pdf is constant. In this particular case the mapping function is defined as:\n",
    "\n",
    "$$T(x) = \\sum_{x_i \\leq x} p(x_i) \\text{ , where }p(x)\\text{ is a pdf}$$\n",
    "\n",
    "### Exercise 4  (3 points)\n",
    "Implement a function that performs histogram equalization using 256 bins. Use the provided `float_to_int` function to round real (floating point) numbers to natural (integer) numbers. Confirm that it equalizes the histogram and increases contrast. The histogram of the resulting image should approach a constant value as the number of bins goes to infinity. *You may use `np.histogram` to compute the histogram*.\n",
    "\n",
    "**Tip**: use the `range` parameter of `np.histogram` to get a histogram over the range from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a92cc98ae848590c22c157252560e357",
     "grade": false,
     "grade_id": "exercise4_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5110d581652f4f4bbc41f0d5be9cbd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.dates as mdates \n",
    "\n",
    "def float_to_int(f):\n",
    "    return np.int32(f + 0.5)\n",
    "\n",
    "def histogram_equalization(gray_image):\n",
    "    hist, bins = np.histogram(gray_image, bins=256, range=(0, 1))\n",
    "    cdf = np.cumsum(hist)\n",
    "    cdf = cdf / cdf[-1]\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(gray_image, bins[:-1], cdf)\n",
    "    return image_equalized\n",
    "\n",
    "\n",
    "bridge_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"bridge.png\"))\n",
    "bridge_image_equalized = histogram_equalization(bridge_image)\n",
    "\n",
    "helpers.show_images({ \"Input\": bridge_image, \"Your solution (histogram equalization)\": bridge_image_equalized }, nrows = 1, ncols = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "625264decf79b54cc610fea8492a8954",
     "grade": false,
     "grade_id": "cell-df326e285aaa07ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 4\n",
    "After histogram equalization the bars in the histogram should be *roughly* the same size, meaning that each grayscale intensity occurs the same amount of times. The bars will not all be exactly the same length, this is expected behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "596b716ff20b99a8b818691286ce8d1d",
     "grade": false,
     "grade_id": "cell-3e3567a53cba9981",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc6048a3b744da9b4104a70d9cdf887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram_comparison(bridge_image, bridge_image_equalized, right_title=\"Histogram equalization (your solution)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "838efeb2f4f741737f46fb4c6727a73f",
     "grade": true,
     "grade_id": "exercise4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93d00b18768d07acaa5a1f1acbb68974",
     "grade": false,
     "grade_id": "cell-c6337f0503ed5720",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 5 (2 points)\n",
    "Saturation filters are a popular way of making an image appear more vibrant. In the lecture, we discussed how HDR filters aim to reduce the contrast while maintaining the original colors. A saturation filter does the opposite by boosting the colors without blowing up the contrast.\n",
    "\n",
    "For this exercise you are expected to implement a saturation filter similar to the \"gamma compression 2.0\" filter described in the lectures. Compute the image's intensity (as in Ex.1). Then divide the original image by the intensity to retrieve a color layer. Then take the values of the color channels to the power of Gamma (which is typically called a gamma correction). The intensity remains unchanged. Finally compute the resulting image by multiplying the adjusted colors by the intensity.\n",
    "\n",
    "**Note:** You may ignore `RuntimeWarning: invalid value encountered in true_divide` warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b0f571a52f3ca74899fec631a633343",
     "grade": false,
     "grade_id": "exercise5_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GLau\\AppData\\Local\\Temp/ipykernel_15640/2546213840.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  color_image = np.divide(image, np.dstack((gray_image, gray_image, gray_image)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad47ead196b4ba68a4bb5224e0df116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def saturate(image, gamma):\n",
    "    # Decrease brightness\n",
    "    gray_image = rgb_to_gray_scale_numpy(image)\n",
    "    color_image = np.divide(image, np.dstack((gray_image, gray_image, gray_image)))\n",
    "    saturated_image = np.multiply(np.power(color_image, gamma), np.dstack((gray_image, gray_image, gray_image)))\n",
    "\n",
    "    return saturated_image\n",
    "\n",
    "\n",
    "mountains_image = helpers.imread_normalized_float(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"mountains.jpeg\"))\n",
    "mountains_saturated = saturate(mountains_image, 1.5)\n",
    "mountains_desaturated = saturate(mountains_image, 1/5)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Input\": mountains_image,\n",
    "    \"Saturated (your solution)\":  mountains_saturated,\n",
    "    \"Desaturated (your solution)\": mountains_desaturated\n",
    "}, nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccb985dadae1ab421c02c66537a221e0",
     "grade": false,
     "grade_id": "cell-e1a4a0593ae8e51c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 5\n",
    "If you implemented exercise 5 correctly then your saturated image should appear more saturized (and yellow), while the desaturated image appears more gray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca0dcf3407481ba12e6e460379fcb9e7",
     "grade": true,
     "grade_id": "exercise",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
