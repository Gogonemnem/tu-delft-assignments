{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af228f94b79ae917df26e6ed47e83114",
     "grade": false,
     "grade_id": "cell-af387adbd68bc941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6623dbec7299194f1d88bfbea1a5186d",
     "grade": false,
     "grade_id": "cell-14fc6ce8afcc24d4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Camera Calibration\n",
    "One of the core concepts in computer graphics is going from 2D to 3D or the other way around. In the physical world cameras project the world they see through a set of lenses onto an image sensor. Similarly, in the virtual world we create a mathematical models that describe how points in 3D \"world space\" are mapped onto the virtual sensor (your screen).\n",
    "\n",
    "\n",
    "## Pinhole Camera\n",
    "The simplest and most common model is the pinhole camera model. The camera model gets its name from the \"pinhole\" camera that it is trying to model: a (infinitely) small hole in the wall of a (shoe)box where all light rays converge. In the real-world case the sensor would be positioned behing the pinhole and the image will appear upside down. In the virtual model however we assume that the image plane is positioned in front of the camera.\n",
    "![](https://www.scratchapixel.com/images/upload/cameras/cameraobscura.png)\n",
    "![](https://www.scratchapixel.com/images/upload/cameras/pinholecam4.png)\n",
    "\n",
    "\n",
    "### Perspective Projection\n",
    "The pinhole model applies perspective projection to the image. That is: far away objects look smaller than objects that are nearby. Assume that the camera is centered at the origin and is looking along the z-axis. To achieve perspective projection we need to divide the x and y coordinates of any point by its z coordinate. We cannot achieve this with regular matrix math because it gives us no way of dividing by z. A way we aleviate this problem is by working in the homogeneous coordinate system. Homogeneous coordinates are similar to regular coordinates except that we give them an extra \"unused\" dimension. Whenever we convert from regular to homogeneous coordinates we set the coordinate along this dimension to 1. When we convert to regular coordinates we make sure to divide the position along all axes by the position along this final axis.\n",
    "$$\n",
    "\\vec{v}=\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "By setting the final axis to the position along the $z$ axis (using a transformation matrix) we effectively divide by Z (when converting back to regular coordinates). So the perspective transformation of our simple pinhole camera model can be described by a simple 3x4 matrix ($f$ is the focal length of the camera):\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "f & 0 & 0 &0  \\\\\n",
    "0 & f & 0 &0 \\\\\n",
    "0 & 0 & 1 &0 \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Rotation and translation\n",
    "In the previous example we assumed that the camera was centered at the origin and it was looking along the z-axis. This might be fine for some use cases but assume that we have two cameras (at different positions/orientations): only one can be at the origin. We need to transform the world such that it aligns with the camera. In a virtual world we place the camera in our world by moving/rotating it away from the origin. So to move the camera to the origin we need to transform the world by the inverse of this matrix. \n",
    "\n",
    "Ignoring scaling (and skewing) such a transformation consists of a rotation and translation (movement). While rotations can be described in matrix form with regular coordinates, translations cannot. The problem we face is that we cannot describe a fixed translation (offset) as a multiplication with a points coordinates (which vary from point to point). Again homogeneous coordinates come to the rescue by adding a known (fixed) value to the input coordinates. Assuming that the position along the final axis is $1$ the following matrix describes a translation in 3D:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x+t_x \\\\\n",
    "y+t_y \\\\\n",
    "z+t_z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & t_x \\\\\n",
    "0 & 1 & 0 & t_y \\\\\n",
    "0 & 0 & 1 & t_z \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Finally, we can describe our full pinhole camera model with the following equation:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "f & 0 & 0 \\\\\n",
    "0 & f & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & t_x \\\\\n",
    "0 & 1 & 0 & t_y \\\\\n",
    "0 & 0 & 1 & t_z \\\\\n",
    "%0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "r_{11} & r_{12} & r_{13} & 0 \\\\\n",
    "r_{21} & r_{22} & r_{23} & 0\\\\\n",
    "r_{31} & r_{32} & r_{33} & 0\\\\\n",
    "0 & 0 & 0 & 1\\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\\\\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "f & 0 & 0 \\\\\n",
    "0 & f & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_x \\\\\n",
    "r_{21} & r_{22} & r_{23} & t_y\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_z\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\\\\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "K\n",
    "[R|t]\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\\\\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "P\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In computer vision we say that the projection matrix $K$ contains the camera *intrinsics* and that the rotation/translation matrix $[R|t]$ contains the camera *extrinsics*.\n",
    "\n",
    "### Exercise 5 (2 points)\n",
    "Assuming that we know the full camera matrix $P$ which transforms 3D points into 2D screen coordinates. Implement a function that takes this matrix and a set of 3D points and transforms those points into pixel coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37a1ccbf809b190dbaba730ced4be0c",
     "grade": false,
     "grade_id": "exercise5_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "XYZ = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0]])\n",
    "\n",
    "def project_points(P, XYZ):\n",
    "    projected_points = np.zeros((len(XYZ), 2))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return projected_points\n",
    "\n",
    "P = np.load(os.path.join(helpers.dataset_folder, \"week4\", \"calibration\", \"rubiks_cube_matrix.npy\"))\n",
    "projected_corners = project_points(P, XYZ)\n",
    "\n",
    "rubiks_cube_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week4\", \"calibration\", \"rubiks_cube.png\"))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Projected points\")\n",
    "ax.imshow(rubiks_cube_image, cmap=\"gray\")\n",
    "ax.scatter(projected_corners[:,0], projected_corners[:,1], c=\"red\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eff8c99728e95bbf6c34fe0c8ce65186",
     "grade": false,
     "grade_id": "cell-ee7fe5f2a86bf94e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tests of exercise 5\n",
    "Your method should project the points (red dots) onto the visible corners of the bottom cube that is closest to the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ecfad0fe3bb30b3dc1ed1a897c4103c",
     "grade": true,
     "grade_id": "exercise5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3980ea8b6638917074f60c3cea60b498",
     "grade": false,
     "grade_id": "cell-0972eea88330422c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6 (1 point)\n",
    "To get feeling of how the 3D coordinate system works you should find the 3D coordinates of the 7 visible corners of the Rubiks cube. Add the coordinates of the points to array `XYZ`. If you implemented the previous exercise correctly then you may use the visuals to guide you. The tests for this exercise are hidden because they contain the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70d72b9a1e8506eff34f744a57cf4cf8",
     "grade": false,
     "grade_id": "exercise6_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "XYZ = np.array([[0,0,0],])\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "P = np.load(os.path.join(helpers.dataset_folder, \"week4\", \"calibration\", \"rubiks_cube_matrix.npy\"))\n",
    "projected_corners = project_points(P, XYZ)\n",
    "\n",
    "rubiks_cube_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week4\", \"calibration\", \"rubiks_cube.png\"))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Projected points\")\n",
    "ax.imshow(rubiks_cube_image, cmap=\"gray\")\n",
    "ax.scatter(projected_corners[:,0], projected_corners[:,1], c=\"red\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6fdfff54811c00303e859ec48277b2a",
     "grade": false,
     "grade_id": "cell-3d79a8a4d4a99880",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tests for exercise 6\n",
    "Your array should contain the 3D coordinates of the 7 visible corners of the Rubiks cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7e9f2fbbeeb09696a46cea44f43ff9f",
     "grade": true,
     "grade_id": "exercise6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(XYZ.shape == (7, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "276d7d7f349301fd1b20cc30b9590351",
     "grade": false,
     "grade_id": "cell-6c4918cb1c458cb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding the camera matrix\n",
    "Assume that we have found a couple of points in the image of which we know the 3D (physical) position, either through manual labor or by programmatically (e.g. corner detection). With this information you should be able to find the (3x4) camera matrix $P=K[R|t]$ that transforms 3D points onto the image plane.\n",
    "\n",
    "### Exercise 7 (3 points)\n",
    "Write a function that given the set of 3D points `XYZ` and their corresponding position on the image plane (2D) `xy` computes the matrix $P$ that projects 3D points onto the image plane. Formulate your problem as a linear system $A\\vec{x}=\\vec{b}$ and solve it using `np.linalg.lstsq(A, b)[0]`.\n",
    "\n",
    "$P$ has 3 rows and 4 columns so there are 12 unknowns in total. However, due to the perspective division, we could apply any scaling factor to the matrix and we would still get the same transform (see lecture). We can therefor fix one of the values in the matrix at 1 such that we have to solve for 11 unknowns. *Hint*: Each pair of 3D/2D points should add 2 contraints (rows in matrix $A$) to the linear system.\n",
    "\n",
    "**NOTE:** Your solution does not have to exactly match the reference. As long as the green points (estimation positions) are close to the red ones (actual positions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62547f1492d49f00c8f056eb6662599c",
     "grade": false,
     "grade_id": "exercise7_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "xy = np.array([\n",
    "            [ 213.1027,  170.0499], [ 258.1908,  181.3219],\n",
    "            [ 306.41  ,  193.8464], [ 351.498 ,  183.8268],\n",
    "            [ 382.8092,  155.6468], [ 411.6155,  130.5978],\n",
    "            [ 223.7485,  218.2691], [ 267.5841,  230.7935],\n",
    "            [ 314.5509,  244.5705], [ 357.7603,  235.1771],\n",
    "            [ 387.819 ,  205.1184], [ 415.3728,  178.1908],\n",
    "            [ 234.3943,  263.9834], [ 276.9775,  277.1341],\n",
    "            [ 323.318 ,  291.5372], [ 363.3963,  282.1438],\n",
    "            [ 392.8288,  251.4589], [ 419.1301,  223.9051]])\n",
    "XYZ = np.array([[0, -5, 5], [0, -3, 5], [0, -1, 5], [-1, 0, 5],\n",
    "             [-3, 0, 5], [-5, 0, 5], [0, -5, 3], [0, -3, 3],\n",
    "             [0, -1, 3], [-1, 0, 3], [-3, 0, 3], [-5, 0, 3],\n",
    "             [0, -5, 1], [0, -3, 1], [0, -1, 1], [-1, 0, 1],\n",
    "             [-3, 0, 1], [-5, 0, 1]])\n",
    "\n",
    "\n",
    "def compute_P(XYZ, xy):\n",
    "    assert(len(XYZ) == len(xy))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Make Python shut up about \"FutureWarning: `rcond` parameter will change ...\"\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    P = compute_P(XYZ, xy) # Use point pairs XYZ/xy to guess the matrix\n",
    "    \n",
    "# Project XYZ to the screen to confirm\n",
    "projected_corners = project_points(P, XYZ)\n",
    "\n",
    "checkerboard_cube_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week4\", \"calibration\", \"checkerboard_cube.jpg\"))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Red = known 2D points, Green = projected 3D points\")\n",
    "ax.imshow(checkerboard_cube_image, cmap=plt.get_cmap('gray'))\n",
    "ax.scatter(xy[:,0], xy[:,1], c=\"red\")\n",
    "ax.scatter(projected_corners[:,0], projected_corners[:,1], c=\"green\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9400170d131946262ee82f6d4e7d410a",
     "grade": false,
     "grade_id": "cell-5e8a8b6b8a83cc2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tests for exercise 7\n",
    "This tests if the correctness of the computed matrix by projecting the points to screen space (using your solution to `project_points` from exercise 5). The points that were used for calibration should be projected very close to their actual positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "098baa6e1481575a7de1af4eb7d3104c",
     "grade": true,
     "grade_id": "exercise7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# === Points used for both calibration & testing ===\n",
    "xy = np.array([[ 213.1027,  170.0499], [ 258.1908,  181.3219],\n",
    "            [ 306.41  ,  193.8464], [ 351.498 ,  183.8268],\n",
    "            [ 382.8092,  155.6468], [ 411.6155,  130.5978],\n",
    "            [ 223.7485,  218.2691], [ 267.5841,  230.7935],\n",
    "            [ 314.5509,  244.5705], [ 357.7603,  235.1771],\n",
    "            [ 387.819 ,  205.1184], [ 415.3728,  178.1908],\n",
    "            [ 234.3943,  263.9834], [ 276.9775,  277.1341],\n",
    "            [ 323.318 ,  291.5372], [ 363.3963,  282.1438],\n",
    "            [ 392.8288,  251.4589], [ 419.1301,  223.9051]])\n",
    "XYZ = np.array([[0, -5, 5], [0, -3, 5], [0, -1, 5], [-1, 0, 5],\n",
    "             [-3, 0, 5], [-5, 0, 5], [0, -5, 3], [0, -3, 3],\n",
    "             [0, -1, 3], [-1, 0, 3], [-3, 0, 3], [-5, 0, 3],\n",
    "             [0, -5, 1], [0, -3, 1], [0, -1, 1], [-1, 0, 1],\n",
    "             [-3, 0, 1], [-5, 0, 1]])\n",
    "\n",
    "\n",
    "# Make Python shut up about \"FutureWarning: `rcond` parameter will change ...\"\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    P = compute_P(XYZ, xy) # Use point pairs XYZ/xy to guess the matrix\n",
    "\n",
    "# Project XYZ to the screen to confirm\n",
    "projected_points = project_points(P, XYZ)\n",
    "# Input points projected back to the screen should have a low error\n",
    "print(f\"Average squared distance between actual calibration points and reprojected points: {helpers.SSD_per_pixel(xy, projected_points)}\")\n",
    "assert(helpers.SSD_per_pixel(xy, projected_points) < 0.15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
