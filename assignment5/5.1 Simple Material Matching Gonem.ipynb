{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8aee401358bb132db9a6b2ad3ef8e9fe",
     "grade": false,
     "grade_id": "cell-acf84d0114f25bea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "import gfx\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0ab806ef71a396284484440267e8141",
     "grade": false,
     "grade_id": "cell-c6577eb3b95ec4dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Material matching\n",
    "In the previous weeks you learned how a depth map can be reconstructed from a set of images. There are also multi-view stereo algorithms that output a 3D surface instead of a point cloud (collection of 3D points). In those cases it is often desirable to capture not only the shape of an object but also its appearance.\n",
    "\n",
    "Capturing the surface appearance of on object might seem simple: just get the pixel values of the images used for reconstruction. This does not work however when viewing the virtual object from different angles. Furthermore, we would implicitely capture the scenes lighting with no way to change it. Instead we want to capture the way the surface reacts to light.\n",
    "\n",
    "To capture the surface appearance we could take many pictures (from different angles and with different light directions) and store the reflectance in a look-up table. This would however not be a very efficient process as it requires a lot of time and compute resources. A more effective way of capturing the reflectance is to fit it to a mathematical model.\n",
    "\n",
    "Visualizing objects with different materials has been an active research topic in computer graphics since its inception. We use mathematical models (Bidirectional Reflection Distribution Function or BRDF for short) to model how light reflects of a surface. By changing the parameters of these models many different materials can be represented. The goal of material matching is to match a mathematical model to real world appearance by finding these parameters.\n",
    "\n",
    "## Renderer\n",
    "Usually material matching would come at the end of the multi-view stereo pipeline. But for educational purposes we have chosen to generate input data directly using a small renderer instead. A renderer is a piece of software that generates images given a description of a virtual scene and camera. The `render(camera, sphere, light, brdf, width, height)` function will generate an image as seen from the camera of the given sphere with the given light and surface reflection function. This way the input does not contain any measurement noise and it becomes easy to verify whether a solution is correct or not.\n",
    "\n",
    "The render function will return three distinct image. The first image contains the familiar Red, Green, and Blue colors. The second image stores for each pixel a 3D position in space: the location of the surface of the sphere at that pixel. Finally, the third image stores for each pixel a normal vector: the orientation of the surface. An example of the three images are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ada22c9e9a380b4484377e3dfc4ea5c",
     "grade": false,
     "grade_id": "renderer",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "camera = gfx.Camera(gfx.Vec3(0, 0, -5), gfx.Vec3(0, 0, 0), gfx.Vec3(0, 1, 0), 45.0, 1.0)\n",
    "sphere = gfx.Sphere(gfx.Vec3(0, 0, 0), 1.5)\n",
    "light = gfx.DirectionalLight(gfx.Vec3(0, 0, 1), gfx.Vec3(1, 1, 1))\n",
    "brdf = gfx.PhongBRDF(gfx.Vec3(0.6, 0.8, 0.4), gfx.Vec3(0.2, 0.3, 0.15), 9)\n",
    "\n",
    "# Because of JIT compilation the first run is slow but every invocation afterwards is fast.\n",
    "%time colors, positions, normals = gfx.render(camera, sphere, light, brdf, 256, 256)\n",
    "%time colors, positions, normals = gfx.render(camera, sphere, light, brdf, 256, 256)\n",
    "%time colors, positions, normals = gfx.render(camera, sphere, light, brdf, 256, 256)\n",
    "helpers.show_images({\n",
    "    \"Color\": np.clip(colors, 0, 1),\n",
    "    \"Position\": (positions+2.5)/5,\n",
    "    \"Normal\": np.abs(normals)\n",
    "}, nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfca3264494904930bc9ef265dc24c22",
     "grade": false,
     "grade_id": "cell-efabebf32a4996cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Python / Performance\n",
    "Because of performance reasons the renderer is again implemented using Numba to (JIT) compile the Python code. We provide some helper functions in the `gfx` file to create/operate with 3D vectors (represented as Numpy arrays). The `gfx` file also contains all classes necessary to describe a scene (`Sphere`, `Camera`, `PointLight`, `PhongBRDF`).\n",
    "\n",
    "**Do following code is not supposed to run, it's only a list of the provided functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b0e395cac71baf8b0e02f973b52a0b6",
     "grade": false,
     "grade_id": "cell-dcfb347d7c5703c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def this_does_not_run():\n",
    "    a = gfx.Vec3(0, 1, 2) # Equivalent to: np.array([0, 1, 2], np.float32)\n",
    "\n",
    "    sphere = gfx.Sphere(center, radius) # Create a sphere at center with radius\n",
    "\n",
    "    camera = gfx.Camera(...) # Create camera (always done for you)\n",
    "    pos = camera.position() # Returns camera position as np.array\n",
    "\n",
    "    light = gfx.PointLight(position, intensity) # Create a infinitely small point of light at position with a given intensity (color)\n",
    "    # For any given point in the scene, compute the direction of the incoming light (normalized vector from point3D towards light)\n",
    "    #  and the intensity (color) of the light at that point\n",
    "    direction, intensity = light.light_at_point(point3D)\n",
    "\n",
    "    # Compute reflection ray for given normal and light direction (pointing away from the normal)\n",
    "    R = gfx.reflect(light_vec, normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f5efdebef34e16107ce845667f0072b",
     "grade": false,
     "grade_id": "cell-302d160e33979d62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Phong Material Model\n",
    "One of the most well known light reflectance models is the Phong reflectance function. It separates the light interaction into two parts: diffuse and specular reflections. Diffuse reflections scatter the incoming light in all directions resulting in a matte appearance. Specular reflections cause shiny highlights (like a mirror). The Phong model is written as:\n",
    "\n",
    "$$\n",
    "C = k_d I (L \\cdot N) + k_s I (E \\cdot R)^t\n",
    "$$\n",
    "\n",
    "Here $C$ is the color of the pixel, $I$ is the color of the incoming light, $L$ is the incoming light direction (pointing towards the light source), $N$ is the surface normal, $E$ is the eye direction and $R$ is reflected light vector ($R=2(L \\cdot N)N - L$, provided by `gfx.reflect(N, L)`). *Both dot products should be clamped to prevent negative values* (normal is pointing away from $L$ or $R$). The parameters are the diffuse reflection color $k_d$, the specular reflectance color $k_s$ and the shininess $t$ which controls the size and brightness of the specular highlight.\n",
    "\n",
    "### Exercise 3 (2 points)\n",
    "Your job is to find a material which matches the appearance of the sphere in the given image. Find the parameters $k_s$ and $k_d$ of the Phong model that were used to render the images by formulating the problem as a linear system and finding the least squares solution. Each pixel that shows the sphere (= not background pixels) should add contraints to the linear system. Assume for this exercise that the given $t$ is correct.\n",
    "\n",
    "The colors, positions and normals are all given as images. Background pixels an empty normal vector (`N = [0, 0, 0]`). The light is provided so that you can compute the incoming light direction/color at any point. Use `light_direction, light_color = light.light_at_point(point)`. Recall that the view vector of the Phong model should be normalized (length 1) and point from the surface towards the camera.\n",
    "\n",
    "Construct a linear system to find $k_d$ and $k_s$ and solve it using `np.linalg.lstsq(A, b)[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50d9772bc6db388f70fed318e6b1acee",
     "grade": false,
     "grade_id": "exercise3_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solve_phong_kd_ks(colors, positions, normals, t, camera_pos, light):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "width = height = 128\n",
    "camera = gfx.Camera(gfx.Vec3(0, 0, -5), gfx.Vec3(0, 0, 0), gfx.Vec3(0, 1, 0), 45.0, 1.0)\n",
    "sphere = gfx.Sphere(gfx.Vec3(0, 0, 0), 1.5)\n",
    "light = gfx.DirectionalLight(gfx.Vec3(0, 0, 1), gfx.Vec3(1, 1, 1))\n",
    "\n",
    "kd = gfx.Vec3(0.6, 0.2, 0.3)\n",
    "ks = gfx.Vec3(0.3, 0.5, 0.2)\n",
    "t = 7\n",
    "brdf = gfx.PhongBRDF(kd, ks, t)\n",
    "\n",
    "colors, positions, normals = gfx.render(camera, sphere, light, brdf, width, height)\n",
    "kd_estimate, ks_estimate = solve_phong_kd_ks(colors, positions, normals, t, camera.position, light)\n",
    "\n",
    "print(f\"Your estimated parameters: kd={kd_estimate}, ks={ks_estimate}\")\n",
    "print(f\"Actual parameters: kd={kd}, ks={ks}\\n\")\n",
    "matched_image, _, _ = gfx.render(camera, sphere, light, gfx.PhongBRDF(kd_estimate.astype(np.float32), ks_estimate.astype(np.float32), t), width, height)\n",
    "\n",
    "print(f\"SSD per pixel: {helpers.SSD_per_pixel(colors, matched_image)}\")\n",
    "helpers.show_images({ \"Input\": colors, \"Matched parameters\": matched_image }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09a81b8ca709e81a5cdc55a9f8564fbb",
     "grade": false,
     "grade_id": "cell-ab116852038c7e7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tests of exercise 3\n",
    "The parameters that your solution picked should result in an image that is extremely close to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13c6fb2a5c8fcbfd4cbfed001ffb15c4",
     "grade": true,
     "grade_id": "exercise3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0b71ad78a0f1516098d0e5f83bfa8f0",
     "grade": false,
     "grade_id": "cell-cf020f5d85a7598f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Computing shininess\n",
    "Finding $k_d$ and $k_s$ when $t$ is known is simple since the reflectance function (and thus the final color output) is linear with respect to $k_d$ and $k_s$. The shininess term $t$ does not have a linear relation to the output. This problem is very common in more complex reflection models which are never just a linear blend of parameters.\n",
    "\n",
    "$$\n",
    "k_d I (L \\cdot N) + k_s I (E \\cdot R)^t\n",
    "$$\n",
    "\n",
    "Assume that we know $k_d$ and $k_s$, making $t$ the only unknown variable. We can reformulate the Phong formula (above) such that it states $t=\\text{...}$ . With this we can estimate $t$ for every pixel & color channel. Take the average over all (non background) pixels to get an accurate estimate of the shininess value $t$ of the sphere.\n",
    "\n",
    "### Exercise 4 (2 points)\n",
    "Implement a function that computes $t$ given $k_d$ and $k_s$ using the method described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8ac9b08d1cd8ffa6d0cab885b87822f",
     "grade": false,
     "grade_id": "exercise4_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solve_phong_t(colors, positions, normals, camera_pos, light, kd, ks):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "width = height = 128\n",
    "camera = gfx.Camera(gfx.Vec3(0, 0, -5), gfx.Vec3(0, 0, 0),gfx. Vec3(0, 1, 0), 45.0, 1.0)\n",
    "sphere = gfx.Sphere(gfx.Vec3(0, 0, 0), 1.5)\n",
    "light = gfx.DirectionalLight(gfx.Vec3(0, 0, 1), gfx.Vec3(0.5, 0.9, 0.7))\n",
    "\n",
    "kd = gfx.Vec3(0.4, 0.2, 0.7)\n",
    "ks = gfx.Vec3(0.3, 0.5, 0.2)\n",
    "t = 4\n",
    "brdf = gfx.PhongBRDF(kd, ks, t)\n",
    "\n",
    "colors, positions, normals = gfx.render(camera, sphere, light, brdf, width, height)\n",
    "t_estimate = solve_phong_t(colors, positions, normals, camera.position, light, kd, ks)\n",
    "\n",
    "print(f\"Estimated parameters: t={t_estimate}\")\n",
    "print(f\"t error: {np.abs(t - t_estimate)}\")\n",
    "\n",
    "matched_image, _, _ = gfx.render(camera, sphere, light, gfx.PhongBRDF(kd, ks, t_estimate), width, height)\n",
    "helpers.show_images({\n",
    "    \"Input\": colors,\n",
    "    \"Matched parameters\": matched_image\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3cbf9c38773aee41b58f6db74141eca",
     "grade": false,
     "grade_id": "cell-fa0943fe7849c2bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tests of exercise 4\n",
    "Your method should be able to detect the $t$ value with high accuracy ($<0.001$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27eee50ac28511f305751834f859a625",
     "grade": true,
     "grade_id": "exercise4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c09fd74c019e7ffa0b2b0214b7fe9499",
     "grade": false,
     "grade_id": "cell-f18a4a8f445357c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5 (3 points)\n",
    "We now have two functions: one to compute $k_d$ & $k_s$, and one to compute $t$. In practical applications we usually don't know any of these three values. We therefor need to combine the two functions above into a single function which finds values values for $k_d$, $k_s$ and $t$. A simple yet effective approach is to start with an initial guess and then alternating between solving for $k_d$/$k_s$, and $t$.\n",
    "\n",
    "Initialize the unknowns ($k_d$, $k_s$ and $t$) to sensible random values. Alternate between solving for $k_d$/$k_s$ (exercise 3) and $t$ (exercise 4). Stop the process once the image error (`estimate_SSD`) is below the threshold of $0.0001$. The process might get stuck in a local minimum sometimes: it will keep alternating between two states. Detect when this is the case (e.g. the error doesn't get smaller) and restart the process with new initial guesses. Make sure that the returned $k_d$, $k_d$ and $t$ estimates are valid ($k_d$/$k_s$ between $0$ and $1$, $t$ above $0$).\n",
    "\n",
    "**Hint:** try using an initial value of $t$ between $1$ and $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e91457730a8bdf3d0d061ee0c29c34c0",
     "grade": false,
     "grade_id": "exercise5_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(38943)\n",
    "random.seed(9343423)\n",
    "\n",
    "def solve_phong_iterative(camera, sphere, light, image_to_match, positions, normals):\n",
    "    height, width, _ = image_to_match.shape\n",
    "\n",
    "    # Error for a given set of kd/ks/t estimates\n",
    "    def estimate_SSD(kd, ks, t):\n",
    "        brdf = gfx.PhongBRDF(kd, ks, t)\n",
    "        estimated_image, _, _ = gfx.render(camera, sphere, light, brdf, width, height)\n",
    "        return helpers.SSD_per_pixel(image_to_match, estimated_image)\n",
    "        \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Suppress runtime warnings when iteration hits invalid kd/ks/t pair\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=RuntimeWarning)\n",
    "        \n",
    "camera = gfx.Camera(gfx.Vec3(0, 0, -5), gfx.Vec3(0, 0, 0), gfx.Vec3(0, 1, 0), 45.0, 1.0)\n",
    "sphere = gfx.Sphere(gfx.Vec3(0, 0, 0), 1.5)\n",
    "light = gfx.DirectionalLight(gfx.Vec3(0, 0, 1), gfx.Vec3(1, 1, 1))\n",
    "\n",
    "kd = gfx.Vec3(0.4, 0.2, 0.7)\n",
    "ks = gfx.Vec3(0.3, 0.5, 0.2)\n",
    "t = 6\n",
    "width = height = 128\n",
    "image_to_match, positions, normals = gfx.render(camera, sphere, light, gfx.PhongBRDF(kd, ks, t), width, height)\n",
    "\n",
    "%time kd_estimate, ks_estimate, t_estimate = solve_phong_iterative(camera, sphere, light, image_to_match, positions, normals)\n",
    "\n",
    "# Render the image with again at a higher resolution and with the estimated kd/ks/t values\n",
    "print(f\"Estimated values: kd={kd_estimate}, ks={ks_estimate}, t={t_estimate}\")\n",
    "width = height = 128\n",
    "reference_image, _, _ = gfx.render(camera, sphere, light, gfx.PhongBRDF(kd, ks, t), width, height)\n",
    "matched_image, _, _ = gfx.render(camera, sphere, light, gfx.PhongBRDF(kd_estimate, ks_estimate, t_estimate), width, height)\n",
    "\n",
    "print(f\"SSD per pixel: {helpers.SSD_per_pixel(reference_image, matched_image)}\")\n",
    "helpers.show_images({ \"Input\": reference_image, \"Matched image\": matched_image }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe3260c76933b857822c28bfda59df7a",
     "grade": false,
     "grade_id": "cell-8cd2a74fafc73f00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tests of exercise 5\n",
    "Your method should be able to estimate the Phong parameters with $0.0001$ of precision (as measured in the sum of squared differences per pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bceafe8407bcac9e78ce520d1806b7f9",
     "grade": true,
     "grade_id": "exercise5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
